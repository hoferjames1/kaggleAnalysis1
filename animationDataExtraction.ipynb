{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1b389a-01a3-45fe-a1c9-e75c0bb42c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ce4c5f-7f13-4898-9e14-929f6e4858a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf2a26d-4e64-4324-956d-899d79902e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = pd.read_csv('players.csv')\n",
    "\n",
    "#week1_df = pd.read_csv('tracking_week_1.csv')\n",
    "#week2_df = pd.read_csv('tracking_week_2.csv')\n",
    "#week3_df = pd.read_csv('tracking_week_3.csv')\n",
    "#week4_df = pd.read_csv('tracking_week_4.csv')\n",
    "#week5_df = pd.read_csv('tracking_week_5.csv')\n",
    "week6_df = pd.read_csv('tracking_week_6.csv')\n",
    "#week7_df = pd.read_csv('tracking_week_7.csv')\n",
    "#week8_df = pd.read_csv('tracking_week_8.csv')\n",
    "#week9_df = pd.read_csv('tracking_week_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74258225-ba15-4d05-a1e5-6daaf8dfa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes = [week1_df, week2_df, week3_df, week4_df, week5_df, week6_df, week7_df, week8_df, week9_df]\n",
    "dataframes = [week6_df]\n",
    "for df in dataframes:\n",
    "    df['unique_key'] = df['gameId'].astype(str) + '_' + df['playId'].astype(str)\n",
    "\n",
    "# Concatenate the filtered dataframes into a single dataframe\n",
    "full_games_df = pd.concat(dataframes, ignore_index=True)\n",
    "full_games_df = full_games_df[full_games_df['unique_key'] == \"2022101604_1264\"]\n",
    "#week1_df = pd.DataFrame()\n",
    "#week2_df = pd.DataFrame()\n",
    "#week3_df = pd.DataFrame()\n",
    "#week4_df = pd.DataFrame()\n",
    "#week5_df = pd.DataFrame()\n",
    "week6_df = pd.DataFrame()\n",
    "#week7_df = pd.DataFrame()\n",
    "#week8_df = pd.DataFrame()\n",
    "#week9_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3424aa8-6081-4f3d-96cf-57393b804281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the max value in quartile 3. Used to calculate \"max\" acceleration without including outliers.\n",
    "def calcQ3Max(dataset):\n",
    "    # Calculate the deltas between consecutive rows for each group of unique_keys\n",
    "    deltas = dataset.groupby('unique_key')['s'].diff().dropna()\n",
    "    \n",
    "    q1 = np.percentile(deltas, 25) # Calculate the first quartile (Q1)\n",
    "    \n",
    "    q3 = np.percentile(deltas, 75) # Calculate the third quartile (Q3)\n",
    "    \n",
    "    iqr = q3 - q1 # Calculate the interquartile range (IQR)\n",
    "    \n",
    "    upper_bound = q3 + 1.5 * iqr # Define the upper bound for outliers\n",
    "    \n",
    "    q3_data = deltas[deltas <= upper_bound] # Filter values within the Q3 range\n",
    "    \n",
    "    max_in_q3 = np.max(q3_data) # Calculate the maximum value within Q3\n",
    "\n",
    "    return max_in_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ba140c-f084-400a-9220-82d11ed772bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'accel' column, to estimate potential maximum movements from one frame to the next\n",
    "players_df['accel'] = 0 #initialize alternate method of calculating acceleration\n",
    "\n",
    "for player, group in full_games_df.groupby('nflId'):\n",
    "    maxAccel = calcQ3Max(group) #as a function of change in speed from frame to frame\n",
    "    players_df['accel'] = np.where(players_df['nflId'] == player, maxAccel, players_df['accel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44468fae-f5fc-4d3e-919e-5dc592a3f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all rows after tackle takes place\n",
    "def mark_rows_to_clear(group):\n",
    "    max_frame_id = group.loc[group['event'] == 'tackle', 'frameId'].max()\n",
    "    group['rowsToClear'] = np.where(group['frameId'] <= max_frame_id, 1, 0)\n",
    "    return group\n",
    "\n",
    "full_games_df['rowsToClear'] = 0\n",
    "full_games_df = full_games_df.groupby('unique_key').apply(mark_rows_to_clear)\n",
    "full_games_df = full_games_df[full_games_df['rowsToClear'] > 0]\n",
    "full_games_df = full_games_df.drop('rowsToClear', axis=1) \n",
    "\n",
    "# Filter out frames where the ball isn't within 1 yard radius of the ball carrier\n",
    "plays_df = pd.read_csv('plays.csv')\n",
    "plays_df['unique_key'] = plays_df['gameId'].astype(str) + '_' + plays_df['playId'].astype(str)\n",
    "full_games_df = pd.merge(full_games_df, plays_df[['unique_key','possessionTeam', 'defensiveTeam', 'playDescription', 'ballCarrierId', 'prePenaltyPlayResult']], on='unique_key', how='left')\n",
    "\n",
    "def calculate_distance(group):\n",
    "    ball_carrier_rows = group[group['nflId'] == group['ballCarrierId']]\n",
    "    football_rows = group[group['club'] == 'football']\n",
    "\n",
    "    # Select relevant columns early\n",
    "    ball_carrier_cols = ball_carrier_rows[['frameId', 'unique_key', 'x', 'y']]\n",
    "    football_cols = football_rows[['frameId', 'unique_key', 'x', 'y']]\n",
    "\n",
    "    # Merge the ball carrier and football rows based on frameId\n",
    "    merged_df = pd.merge(ball_carrier_cols, football_cols, on=['frameId', 'unique_key'], suffixes=('_ball_carrier', '_football'))\n",
    "\n",
    "    # Calculate the distance between positions\n",
    "    group['dist_2_ball'] = ((merged_df[['x_ball_carrier', 'y_ball_carrier']] - merged_df[['x_football', 'y_football']]) ** 2).sum(axis=1) ** 0.5\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Create an empty column for 'dist_2_ball'\n",
    "full_games_df['dist_2_ball'] = np.nan\n",
    "full_games_df = full_games_df.groupby('unique_key').apply(calculate_distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cbb6558-cd31-441a-8a21-768ff62f2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating potential distance travelled column which reflects current speed plus calculated ability to accelerate in a single frame.\n",
    "accel_column = players_df[['nflId', 'accel']] # Extract the relevant column from players_df\n",
    "\n",
    "full_games_df = pd.merge(full_games_df, accel_column, on='nflId', how='left') # Merge DataFrames based on 'nflId'\n",
    "\n",
    "full_games_df['time'] = pd.to_datetime(full_games_df['time']) # Convert 'time' column to datetime if it's not already\n",
    "\n",
    "def calculate_deltas_within_group(group):# Function to calculate frame durations within each group\n",
    "    group['potDistTravelled'] = group['accel'] + (group['s']/10)\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group based on 'unique_key'\n",
    "full_games_df = full_games_df.groupby('unique_key', group_keys=False).apply(calculate_deltas_within_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96bad511-d385-42fd-a37b-8f29e095c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_closing_speed(v1, h1, v2, h2):\n",
    "    # Convert headings to radians\n",
    "    h1_rad, h2_rad = math.radians(h1), math.radians(h2)\n",
    "\n",
    "    # Calculate closing speed\n",
    "    closing_speed = math.sqrt((v2 * math.cos(h2_rad) - v1 * math.cos(h1_rad))**2 +\n",
    "                              (v2 * math.sin(h2_rad) - v1 * math.sin(h1_rad))**2)\n",
    "\n",
    "    # Include the sign of the relative velocity\n",
    "    closing_speed *= math.copysign(1, v2 * math.cos(h2_rad) - v1 * math.cos(h1_rad))\n",
    "\n",
    "    return closing_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e17349-a785-4be5-b758-ac9bf73633b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAllDistDeltas(group):\n",
    "    columns = ['unique_key', 'frameId', 'primaryTackler', 'secondaryTackler', 'ballCarrier']\n",
    "    new_frames = []\n",
    "    all_frames_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in group['frameId'].unique():\n",
    "        temp_frame = pd.DataFrame(columns=columns)\n",
    "        \n",
    "        currentFrame = group[group['frameId'] == i]\n",
    "\n",
    "        offenseIds = currentFrame[currentFrame['club'] == currentFrame['possessionTeam']]['nflId'].unique()\n",
    "        defenseIds = currentFrame[(currentFrame['club'] != currentFrame['possessionTeam']) & (currentFrame['club'] != 'football')]['nflId'].unique()\n",
    "\n",
    "        distDelta_frame = pd.DataFrame(index=offenseIds, columns=defenseIds)\n",
    "\n",
    "        x_values = currentFrame.set_index('nflId')['x']\n",
    "        y_values = currentFrame.set_index('nflId')['y']\n",
    "\n",
    "        for offenseId in offenseIds:\n",
    "            for defenseId in defenseIds:\n",
    "                x_diff = x_values[offenseId] - x_values[defenseId]\n",
    "                y_diff = y_values[offenseId] - y_values[defenseId]\n",
    "\n",
    "                distance = np.sqrt(x_diff**2 + y_diff**2)\n",
    "                distDelta_frame.loc[offenseId, defenseId] = distance\n",
    "\n",
    "        defRanges = currentFrame.loc[currentFrame['nflId'].isin(defenseIds), ['nflId', 'potDistTravelled']].set_index('nflId')['potDistTravelled']\n",
    "        defHeadings = currentFrame.loc[currentFrame['nflId'].isin(defenseIds), ['nflId', 'o']].set_index('nflId')['o']\n",
    "       \n",
    "        ballCarrierId = currentFrame['ballCarrierId'].head(11)\n",
    "       \n",
    "        if currentFrame['playDirection'].iloc[0] == 'left':\n",
    "            carrierHeading = 270\n",
    "        else:\n",
    "            carrierHeading = 90\n",
    "\n",
    "        carrierProximity = distDelta_frame.loc[distDelta_frame.index == ballCarrierId]\n",
    "        distDelta_frame = distDelta_frame.drop(ballCarrierId.unique(), axis=0, errors='ignore')\n",
    "\n",
    "        minDefDist = distDelta_frame.min(axis=0).T\n",
    "       \n",
    "        ballCarrierId = currentFrame['ballCarrierId'].head(10)\n",
    "        carrierSpeed = currentFrame.loc[currentFrame['nflId'].isin(currentFrame['ballCarrierId'].head(1)), ['nflId', 'potDistTravelled']].set_index('nflId')['potDistTravelled']\n",
    "       \n",
    "        defClosingSpeeds = pd.DataFrame()\n",
    "        for j in defenseIds:\n",
    "            tempDefenderSpeed = defRanges.loc[j]\n",
    "            tempDefenderHeading = defHeadings.loc[j]\n",
    "            closingSpeed = calculate_closing_speed(carrierSpeed, carrierHeading, tempDefenderSpeed, tempDefenderHeading)\n",
    "            defClosingSpeeds.loc[j, 'ClosingSpeed'] = closingSpeed\n",
    "       \n",
    "        carrierApproach = abs(carrierProximity / defClosingSpeeds['ClosingSpeed'])\n",
    "       \n",
    "        possiblePrimarys = np.where(minDefDist < defRanges*0.7878, 100, carrierApproach)\n",
    "        possiblePrimarys = pd.DataFrame(possiblePrimarys, columns=distDelta_frame.columns).T\n",
    "        possiblePrimarys.sort_values(by=possiblePrimarys.columns[0], ascending=True, inplace=True)\n",
    "        # Convert the index to a column of integers\n",
    "        possiblePrimarys.reset_index(inplace=True)\n",
    "        possiblePrimarys['frameId'] = i\n",
    "        # Drop the index column\n",
    "        #possiblePrimarys.drop('index', axis=1, inplace=True)\n",
    "\n",
    "        all_frames_data = all_frames_data.append(possiblePrimarys, ignore_index=True)\n",
    "        primaryTackler = int(possiblePrimarys.index[0])\n",
    "        secondaryTackler = int(possiblePrimarys.index[1])\n",
    "\n",
    "        # Append the frame data to the list\n",
    "        frame_data = [currentFrame['unique_key'].unique()[0], i, primaryTackler, secondaryTackler, ballCarrierId.unique()[0]]\n",
    "        new_frames.append(frame_data)\n",
    "\n",
    "    # Create a new DataFrame from the list of frames\n",
    "    new_group = pd.DataFrame(new_frames, columns=columns)\n",
    "    all_frames_data.to_csv('animationEligibles.csv', index=False)\n",
    "\n",
    "    return new_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97511dc2-6510-491f-bde1-bf952efa5198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1 of 1\n",
      "Total skipped: 0\n"
     ]
    }
   ],
   "source": [
    "final_frames = []\n",
    "totalSkipped = 0\n",
    "unique_keys = full_games_df['unique_key'].unique()\n",
    "\n",
    "for i, key in enumerate(unique_keys, start=1):\n",
    "    try:\n",
    "        subset_df = full_games_df[full_games_df['unique_key'] == key]\n",
    "        subset_df = calcAllDistDeltas(subset_df)\n",
    "        final_frames.append(subset_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped processing key: {key}. Error: {e}\")\n",
    "        totalSkipped += 1\n",
    "\n",
    "    print(f\"Processed: {i} of {len(unique_keys)}\")\n",
    "\n",
    "print(\"Total skipped: \" + str(totalSkipped))\n",
    "\n",
    "#final_dataset = pd.concat(final_frames, ignore_index=True)\n",
    "final_dataset = final_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df50f6-a8d1-4328-aa8d-b85b003ee7b2",
   "metadata": {},
   "source": [
    "# change data frame name and clear up memory\n",
    "full_games_df = final_dataset\n",
    "final_dataset = pd.DataFrame()\n",
    "tackles_df = pd.read_csv('tackles.csv')\n",
    "\n",
    "grouped_df = full_games_df.groupby('unique_key', as_index=False)\n",
    "\n",
    "# Calculate primaryTackler and secondaryTackler DataFrames using agg\n",
    "agg_df = grouped_df.agg({'primaryTackler': lambda x: x.value_counts().idxmax(),\n",
    "                         'secondaryTackler': lambda x: x.value_counts().idxmax()})\n",
    "\n",
    "# Rename the columns\n",
    "agg_df.rename(columns={'primaryTackler': 'primaryTackler', 'secondaryTackler': 'secondaryTackler'}, inplace=True)\n",
    "\n",
    "# Merge the DataFrames based on 'unique_key'\n",
    "tacklers_by_play_df = pd.merge(agg_df[['unique_key', 'primaryTackler']], agg_df[['unique_key', 'secondaryTackler']], on='unique_key')\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "tacklers_by_play_df.columns = ['unique_key', 'primaryTackler', 'secondaryTackler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94960b04-d093-4184-a13e-baf9d473499c",
   "metadata": {},
   "source": [
    "\n",
    "total_plays = len(tackles_df)\n",
    "\n",
    "full_games_df = tacklers_by_play_df\n",
    "# Create a new column 'unique_key' in tackles_df by combining 'gameId' + \"_\" + 'playId'\n",
    "tackles_df['unique_key'] = tackles_df['gameId'].astype(str) + \"_\" + tackles_df['playId'].astype(str)\n",
    "\n",
    "# Rename 'nflId' column in tackles_df to 'actualTackler'\n",
    "tackles_df.rename(columns={'nflId': 'actualTackler'}, inplace=True)\n",
    "\n",
    "# Join tackles_df['actualTackler'] to full_games_df on 'unique_key'\n",
    "full_games_df = full_games_df.merge(tackles_df[['unique_key', 'actualTackler', 'tackle']], how='left', on='unique_key')\n",
    "\n",
    "# Drop rows where 'tackle' is not equal to 1\n",
    "full_games_df = full_games_df[full_games_df['tackle'] == 1]\n",
    "\n",
    "tackler_ratios_df = pd.DataFrame()\n",
    "\n",
    "# Create a list of all unique values in 'primaryTackler', 'secondaryTackler', and 'actualTackler'\n",
    "unique_ids = list(set(full_games_df['primaryTackler'].unique()) |\n",
    "                     set(full_games_df['secondaryTackler'].unique()) |\n",
    "                     set(full_games_df['actualTackler'].unique()))\n",
    "\n",
    "for i in unique_ids:\n",
    "    try:\n",
    "        subset1 = full_games_df[(full_games_df['primaryTackler'] == i) & (full_games_df['actualTackler'] == i)]\n",
    "        success_as_prime = len(subset1)\n",
    "        \n",
    "        subset2 = full_games_df[(full_games_df['secondaryTackler'] == i) & (full_games_df['actualTackler'] == i)]\n",
    "        success_as_second = len(subset2)\n",
    "        \n",
    "        subset3 = full_games_df[full_games_df['primaryTackler'] == i]\n",
    "        count_as_prime = len(subset3)\n",
    "        \n",
    "        subset4 = full_games_df[full_games_df['secondaryTackler'] == i]\n",
    "        count_as_second = len(subset4)\n",
    "\n",
    "        subset5 = full_games_df[full_games_df['actualTackler'] == i]\n",
    "        player_tackles = len(subset5)\n",
    "\n",
    "        contributionRate = player_tackles/total_plays\n",
    "        prime_ratio = success_as_prime / count_as_prime * contributionRate * 1000\n",
    "        second_ratio = success_as_second / count_as_second * contributionRate * 1000\n",
    "        tackler_ratios_df = tackler_ratios_df.append({'ID': i, 'Ace Score': prime_ratio, 'Wingman Score': second_ratio, 'Player Tackles':player_tackles}, ignore_index=True)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "# Sort the DataFrame by 'Ace Score' column in descending order\n",
    "tackler_ratios_df = tackler_ratios_df.sort_values(by=['Ace Score', 'Wingman Score'], ascending=[False, False])\n",
    "# Set option to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Print the DataFrame with ratios\n",
    "print(\"\\nTackler Ratios DataFrame (Descending Order by Ace Score):\")\n",
    "print(tackler_ratios_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f680709-011a-4661-b4b9-8db635a2389b",
   "metadata": {},
   "source": [
    "tackler_subset = tackler_ratios_df.head(10)\n",
    "player_info = pd.read_csv('playersMod.csv')\n",
    "\n",
    "merged_df = tackler_subset.merge(player_info, left_on='ID', right_on='nflId', how='left')\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dfb7df-b7b8-4312-89f1-2bfbf64e1f19",
   "metadata": {},
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total run time: {elapsed_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
